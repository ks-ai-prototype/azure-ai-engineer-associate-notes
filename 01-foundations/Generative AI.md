# Generative AI â€“ Complete Notes with Examples

---

## 1. History of Generative AI

Generative AI is a branch of Artificial Intelligence that focuses on **creating new content** rather than only analyzing or classifying existing data.

### Evolution Timeline

- **1950sâ€“1980s: Rule-Based AI**
  - Hard-coded rules
  - No learning or generation

- **1990sâ€“2000s: Statistical Machine Learning**
  - Probabilistic models
  - Limited creativity

- **2014: Generative Adversarial Networks (GANs)**
  - First major success in image generation

- **2017: Transformer Architecture**
  - Introduced attention mechanism
  - Enabled parallel processing

- **2020â€“Present: Large Language Models (LLMs)**
  - Text, code, reasoning, and multimodal generation

ğŸ“Œ **Exam Tip:**  
Modern Generative AI exists because of **Transformers + Big Data + High Compute (GPUs)**.

---

## 2. What is Generative AI?

**Generative AI** is an AI system that:
- Learns patterns from training data
- Generates **new, original content**
- Produces probabilistic (non-deterministic) outputs

### What Generative AI Can Generate
- Text (chat, summaries, emails)
- Code (Python, SQL, Java)
- Images and designs
- Audio and video

### What Generative AI is NOT
- âŒ Rule-based system
- âŒ Search engine
- âŒ Traditional classifier

---

## 3. How Generative AI Works (Core Idea)

Generative AI models:
- Break text into **tokens**
- Predict the **next most likely token**
- Repeat prediction until output is complete

ğŸ“Œ The model does **not understand** like humans â€” it predicts probabilities.

---

## 4. Prompts

### What is a Prompt?

A **prompt** is the instruction or input provided to a Generative AI model to guide its response.

A prompt may include:
- Task instruction
- Context
- Constraints
- Examples

### Prompt Example


ğŸ“Œ **Exam Tip:**  
Clear prompts = better outputs.

---

## 5. LLM Inputs

Large Language Models internally process:

1. **System Instructions**
   - Define behavior and rules

2. **User Prompt**
   - Main task or question

3. **Context / History**
   - Previous conversation or documents

4. **Parameters**
   - Temperature (creativity)
   - Max tokens (output length)

ğŸ“Œ Higher temperature â†’ more creative  
ğŸ“Œ Lower temperature â†’ more consistent

---

## 6. LLM Outputs

LLM outputs are:
- Generated token-by-token
- Context-aware
- Probabilistic

### Output Types
- Text
- Code
- Structured data (JSON)
- Reasoned responses

ğŸ“Œ Output may vary for the same prompt.

---

## 7. Examples of Generative AI

### Example 1: Text Generation

**Prompt:**
Write a professional email requesting one day of leave.

**Output:**
```
Dear Manager,
I would like to request leave for one day due to personal reasons.
Please let me know if this works for you.

Thank you.
```
---

### Example 2: Code Generation

**Prompt**
Write a Python function to check if a number is even.

**Output**
```python
def is_even(number):
    return number % 2 == 0
```
### Example 3: Summarization

**Prompt**

Summarize the following document in 3 bullet points.


**Output**
```
â€¢ Key objective of the document 
â€¢ Major findings and risks
â€¢ Final recommendations

```
### Example 4: Question Answering

**Prompt**

What is the difference between Generative AI and Traditional AI?


**Output**
```text
Traditional AI focuses on prediction or classification,
while Generative AI creates new content such as text, images, or code.
```

## 8. Prompt â†’ LLM â†’ Output Flow (Diagram)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â”‚   Prompt    â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prompt Processing       â”‚
â”‚  â€¢ Tokenization          â”‚
â”‚  â€¢ Context embedding     â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Large Language Model    â”‚
â”‚  (Transformer Network)  â”‚
â”‚  â€¢ Attention mechanism  â”‚
â”‚  â€¢ Probability scoring  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Token Generation        â”‚
â”‚  â€¢ Next token predicted  â”‚
â”‚  â€¢ Repeated until stop   â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Output    â”‚
â”‚ (Text /     â”‚
â”‚  Code /     â”‚
â”‚  JSON)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
## 9. Common Exam Traps

```
| Question                               | Correct Answer             |
| -------------------------------------- | -------------------------- |
| Is Generative AI deterministic?        | âŒ No                       |
| Does it browse the internet?           | âŒ No                       |
| Is output always correct?              | âŒ No                       |
| Are prompts important?                 | âœ… Yes                      |
| Is model trained during every request? | âŒ No (only inference runs) |
